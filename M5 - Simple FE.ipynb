{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, sys, gc, time, warnings, pickle, psutil, random\n",
    "from fastai import *\n",
    "from fastai.tabular import *\n",
    "from math import ceil\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple \"Memory profilers\" to see memory usage\n",
    "def get_memory_usage():\n",
    "    return np.round(psutil.Process(os.getpid()).memory_info()[0]/2.**30, 2) \n",
    "        \n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f%s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f%s%s\" % (num, 'Yi', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Memory Reducer\n",
    "# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n",
    "# :verbose                                        # type: bool\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                       df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merging by concat to not lose dtypes\n",
    "def merge_by_concat(df1, df2, merge_on):\n",
    "    merged_gf = df1[merge_on]\n",
    "    merged_gf = merged_gf.merge(df2, on=merge_on, how='left')\n",
    "    new_columns = [col for col in list(merged_gf) if col not in merge_on]\n",
    "    df1 = pd.concat([df1, merged_gf[new_columns]], axis=1)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "########################### Vars\n",
    "#################################################################################\n",
    "TARGET = 'sales'         # Our main target\n",
    "END_TRAIN = 1913         # Last day in train set\n",
    "MAIN_INDEX = ['id','d']  # We can identify item by these columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Load Data\n",
    "#################################################################################\n",
    "print('Load Main Data')\n",
    "\n",
    "# Here are reafing all our data \n",
    "# without any limitations and dtype modification\n",
    "train_df = pd.read_csv('/home/shanmugam/fastai/m5/sales_train_validation.csv')\n",
    "prices_df = pd.read_csv('/home/shanmugam/fastai/m5/sell_prices.csv')\n",
    "calendar_df = pd.read_csv('/home/shanmugam/fastai/m5/calendar.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Make Grid\n",
    "#################################################################################\n",
    "print('Create Grid')\n",
    "\n",
    "# We can tranform horizontal representation \n",
    "# to vertical \"view\"\n",
    "# Our \"index\" will be 'id','item_id','dept_id','cat_id','store_id','state_id'\n",
    "# and labels are 'd_' coulmns\n",
    "\n",
    "index_columns = ['id','item_id','dept_id','cat_id','store_id','state_id']\n",
    "grid_df = pd.melt(train_df, \n",
    "                  id_vars = index_columns, \n",
    "                  var_name = 'd', \n",
    "                  value_name = TARGET)\n",
    "\n",
    "# If we look on train_df we se that \n",
    "# we don't have a lot of traning rows\n",
    "# but each day can provide more train data\n",
    "print('Train rows:', len(train_df), len(grid_df))\n",
    "\n",
    "# To be able to make predictions\n",
    "# we need to add \"test set\" to our grid\n",
    "add_grid = pd.DataFrame()\n",
    "for i in range(1,29):\n",
    "    temp_df = train_df[index_columns]\n",
    "    temp_df = temp_df.drop_duplicates()\n",
    "    temp_df['d'] = 'd_'+ str(END_TRAIN+i)\n",
    "    temp_df[TARGET] = np.nan\n",
    "    add_grid = pd.concat([add_grid,temp_df])\n",
    "\n",
    "grid_df = pd.concat([grid_df,add_grid])\n",
    "grid_df = grid_df.reset_index(drop=True)\n",
    "\n",
    "# Remove some temoprary DFs\n",
    "del temp_df, add_grid\n",
    "\n",
    "# We will not need original train_df\n",
    "# anymore and can remove it\n",
    "del train_df\n",
    "\n",
    "# You don't have to use df = df construction\n",
    "# you can use inplace=True instead.\n",
    "# like this\n",
    "# grid_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Let's check our memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Original grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "\n",
    "# We can free some memory \n",
    "# by converting \"strings\" to categorical\n",
    "# it will not affect merging and \n",
    "# we will not lose any valuable data\n",
    "for col in index_columns:\n",
    "    grid_df[col] = grid_df[col].astype('category')\n",
    "\n",
    "# Let's check again memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Reduced grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Product Release date\n",
    "#################################################################################\n",
    "print('Release week')\n",
    "\n",
    "# It seems that leadings zero values\n",
    "# in each train_df item row\n",
    "# are not real 0 sales but mean\n",
    "# absence for the item in the store\n",
    "# we can safe some memory by removing\n",
    "# such zeros\n",
    "\n",
    "# Prices are set by week\n",
    "# so it we will have not very accurate release week \n",
    "release_df = prices_df.groupby(['store_id','item_id'])['wm_yr_wk'].agg(['min']).reset_index()\n",
    "release_df.columns = ['store_id','item_id','release']\n",
    "\n",
    "# Now we can merge release_df\n",
    "grid_df = merge_by_concat(grid_df, release_df, ['store_id','item_id'])\n",
    "del release_df\n",
    "\n",
    "# We want to remove some \"zeros\" rows\n",
    "# from grid_df \n",
    "# to do it we need wm_yr_wk column\n",
    "# let's merge partly calendar_df to have it\n",
    "grid_df = merge_by_concat(grid_df, calendar_df[['wm_yr_wk','d']], ['d'])\n",
    "                      \n",
    "# Now we can cutoff some rows \n",
    "# and safe memory \n",
    "grid_df = grid_df[grid_df['wm_yr_wk']>=grid_df['release']]\n",
    "grid_df = grid_df.reset_index(drop=True)\n",
    "\n",
    "# Let's check our memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Original grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "\n",
    "# Should we keep release week \n",
    "# as one of the features?\n",
    "# Only good CV can give the answer.\n",
    "# Let's minify the release values.\n",
    "# Min transformation will not help here \n",
    "# as int16 -> Integer (-32768 to 32767)\n",
    "# and our grid_df['release'].max() serves for int16\n",
    "# but we have have an idea how to transform \n",
    "# other columns in case we will need it\n",
    "grid_df['release'] = grid_df['release'] - grid_df['release'].min()\n",
    "grid_df['release'] = grid_df['release'].astype(np.int16)\n",
    "\n",
    "# Let's check again memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Reduced grid_df',sizeof_fmt(grid_df.memory_usage(index=True).sum())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Save part 1\n",
    "#################################################################################\n",
    "print('Save Part 1')\n",
    "\n",
    "# We have our BASE grid ready\n",
    "# and can save it as pickle file\n",
    "# for future use (model training)\n",
    "grid_df.to_pickle('grid_part_1.pkl')\n",
    "\n",
    "print('Size:', grid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Prices\n",
    "#################################################################################\n",
    "print('Prices')\n",
    "\n",
    "# We can do some basic aggregations\n",
    "prices_df['price_max'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('max')\n",
    "prices_df['price_min'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('min')\n",
    "prices_df['price_std'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('std')\n",
    "prices_df['price_mean'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('mean')\n",
    "\n",
    "# and do price normalization (min/max scaling)\n",
    "prices_df['price_norm'] = prices_df['sell_price']/prices_df['price_max']\n",
    "\n",
    "# Some items are can be inflation dependent\n",
    "# and some items are very \"stable\"\n",
    "prices_df['price_nunique'] = prices_df.groupby(['store_id','item_id'])['sell_price'].transform('nunique')\n",
    "prices_df['item_nunique'] = prices_df.groupby(['store_id','sell_price'])['item_id'].transform('nunique')\n",
    "\n",
    "# I would like some \"rolling\" aggregations\n",
    "# but would like months and years as \"window\"\n",
    "calendar_prices = calendar_df[['wm_yr_wk','month','year']]\n",
    "calendar_prices = calendar_prices.drop_duplicates(subset=['wm_yr_wk'])\n",
    "prices_df = prices_df.merge(calendar_prices[['wm_yr_wk','month','year']], on=['wm_yr_wk'], how='left')\n",
    "del calendar_prices\n",
    "\n",
    "# Now we can add price \"momentum\" (some sort of)\n",
    "# Shifted by week \n",
    "# by month mean\n",
    "# by year mean\n",
    "prices_df['price_momentum'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id'])['sell_price'].transform(lambda x: x.shift(1))\n",
    "prices_df['price_momentum_m'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id','month'])['sell_price'].transform('mean')\n",
    "prices_df['price_momentum_y'] = prices_df['sell_price']/prices_df.groupby(['store_id','item_id','year'])['sell_price'].transform('mean')\n",
    "\n",
    "del prices_df['month'], prices_df['year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df = reduce_mem_usage(grid_df)\n",
    "prices_df = reduce_mem_usage(prices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Merge prices and save part 2\n",
    "#################################################################################\n",
    "print('Merge prices and save part 2')\n",
    "\n",
    "# Merge Prices\n",
    "original_columns = list(grid_df)\n",
    "grid_df = grid_df.merge(prices_df, on=['store_id','item_id','wm_yr_wk'], how='left')\n",
    "keep_columns = [col for col in list(grid_df) if col not in original_columns]\n",
    "grid_df = grid_df[MAIN_INDEX+keep_columns]\n",
    "grid_df = reduce_mem_usage(grid_df)\n",
    "\n",
    "# Safe part 2\n",
    "grid_df.to_pickle('grid_part_2.pkl')\n",
    "print('Size:', grid_df.shape)\n",
    "\n",
    "# We don't need prices_df anymore\n",
    "del prices_df\n",
    "\n",
    "# We can remove new columns\n",
    "# or just load part_1\n",
    "grid_df = pd.read_pickle('grid_part_1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Merge calendar\n",
    "#################################################################################\n",
    "grid_df = grid_df[MAIN_INDEX]\n",
    "\n",
    "# Merge calendar partly\n",
    "icols = ['date',\n",
    "         'd',\n",
    "         'event_name_1',\n",
    "         'event_type_1',\n",
    "         'event_name_2',\n",
    "         'event_type_2',\n",
    "         'snap_CA',\n",
    "         'snap_TX',\n",
    "         'snap_WI']\n",
    "\n",
    "grid_df = grid_df.merge(calendar_df[icols], on=['d'], how='left')\n",
    "\n",
    "# Minify data\n",
    "# 'snap_' columns we can convert to bool or int8\n",
    "icols = ['event_name_1',\n",
    "         'event_type_1',\n",
    "         'event_name_2',\n",
    "         'event_type_2',\n",
    "         'snap_CA',\n",
    "         'snap_TX',\n",
    "         'snap_WI']\n",
    "for col in icols:\n",
    "    grid_df[col] = grid_df[col].astype('category')\n",
    "\n",
    "# Convert to DateTime\n",
    "grid_df['date'] = pd.to_datetime(grid_df['date'])\n",
    "\n",
    "# Make some features from date\n",
    "grid_df['tm_d'] = grid_df['date'].dt.day.astype(np.int8)\n",
    "grid_df['tm_w'] = grid_df['date'].dt.week.astype(np.int8)\n",
    "grid_df['tm_m'] = grid_df['date'].dt.month.astype(np.int8)\n",
    "grid_df['tm_y'] = grid_df['date'].dt.year\n",
    "grid_df['tm_y'] = (grid_df['tm_y'] - grid_df['tm_y'].min()).astype(np.int8)\n",
    "grid_df['tm_wm'] = grid_df['tm_d'].apply(lambda x: ceil(x/7)).astype(np.int8)\n",
    "\n",
    "grid_df['tm_dw'] = grid_df['date'].dt.dayofweek.astype(np.int8)\n",
    "grid_df['tm_w_end'] = (grid_df['tm_dw']>=5).astype(np.int8)\n",
    "\n",
    "# Remove date\n",
    "#del grid_df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Save part 3 (Dates)\n",
    "#################################################################################\n",
    "print('Save part 3')\n",
    "\n",
    "# Safe part 3\n",
    "grid_df.to_pickle('grid_part_3.pkl')\n",
    "print('Size:', grid_df.shape)\n",
    "\n",
    "# We don't need calendar_df anymore\n",
    "del calendar_df\n",
    "del grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Some additional cleaning\n",
    "#################################################################################\n",
    "\n",
    "## Part 1\n",
    "# Convert 'd' to int\n",
    "grid_df = pd.read_pickle('grid_part_1.pkl')\n",
    "grid_df['d'] = grid_df['d'].apply(lambda x: x[2:]).astype(np.int16)\n",
    "\n",
    "# Remove 'wm_yr_wk'\n",
    "# as test values are not in train set\n",
    "del grid_df['wm_yr_wk']\n",
    "grid_df.to_pickle('grid_part_1.pkl')\n",
    "\n",
    "del grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Summary\n",
    "#################################################################################\n",
    "\n",
    "# Now we have 3 sets of features\n",
    "grid_df = pd.concat([pd.read_pickle('grid_part_1.pkl'),\n",
    "                     pd.read_pickle('grid_part_2.pkl').iloc[:,2:],\n",
    "                     pd.read_pickle('grid_part_3.pkl').iloc[:,2:]],\n",
    "                     axis=1)\n",
    "                     \n",
    "# Let's check again memory usage\n",
    "print(\"{:>20}: {:>8}\".format('Full Grid',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "print('Size:', grid_df.shape)\n",
    "\n",
    "# 2.5GiB + is is still too big to train our model\n",
    "# (on kaggle with its memory limits)\n",
    "# and we don't have lag features yet\n",
    "# But what if we can train by state_id or shop_id?\n",
    "state_id = 'CA'\n",
    "grid_df = grid_df[grid_df['state_id']==state_id]\n",
    "print(\"{:>20}: {:>8}\".format('Full Grid',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "#           Full Grid:   1.2GiB\n",
    "\n",
    "store_id = 'CA_1'\n",
    "grid_df = grid_df[grid_df['store_id']==store_id]\n",
    "print(\"{:>20}: {:>8}\".format('Full Grid',sizeof_fmt(grid_df.memory_usage(index=True).sum())))\n",
    "#           Full Grid: 321.2MiB\n",
    "\n",
    "# Seems its good enough now\n",
    "# In other kernel we will talk about LAGS features\n",
    "# Thank you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################### Final list of features\n",
    "#################################################################################\n",
    "grid_df = pd.concat([pd.read_pickle('grid_part_1.pkl'),\n",
    "                     pd.read_pickle('grid_part_2.pkl').iloc[:,2:],\n",
    "                     pd.read_pickle('grid_part_3.pkl').iloc[:,2:]],\n",
    "                     axis=1)\n",
    "grid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df = reduce_mem_usage(grid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df.groupby(['store_id','item_id'])['sell_price'].transform('nunique')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1293.97 Mb (0.0% reduction)\n"
     ]
    }
   ],
   "source": [
    "grid_df = pd.read_pickle('grid_df143.pkl')\n",
    "grid_df = reduce_mem_usage(grid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(grid_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    " 'item_id',\n",
    " 'dept_id',\n",
    " 'cat_id',\n",
    " 'store_id',\n",
    " 'state_id',\n",
    " 'd',\n",
    " 'release',\n",
    " 'sell_price',\n",
    " 'price_max',\n",
    " 'price_min',\n",
    " 'price_std',\n",
    " 'price_mean',\n",
    " 'price_norm',\n",
    " 'price_nunique',\n",
    " 'item_nunique',\n",
    " 'price_momentum',\n",
    " 'price_momentum_m',\n",
    " 'price_momentum_y',\n",
    " 'event_name_1',\n",
    " 'event_type_1',\n",
    " 'event_name_2',\n",
    " 'event_type_2',\n",
    " 'snap_CA',\n",
    " 'snap_TX',\n",
    " 'snap_WI',\n",
    " 'tm_d',\n",
    " 'tm_w',\n",
    " 'tm_m',\n",
    " 'tm_y',\n",
    " 'tm_wm',\n",
    " 'tm_dw',\n",
    " 'tm_w_end',\n",
    "'sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['release',\n",
       " 'sell_price',\n",
       " 'price_max',\n",
       " 'price_min',\n",
       " 'price_std',\n",
       " 'price_mean',\n",
       " 'price_norm',\n",
       " 'price_nunique',\n",
       " 'item_nunique',\n",
       " 'price_momentum',\n",
       " 'price_momentum_m',\n",
       " 'price_momentum_y',\n",
       " 'sales']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_m = ['snap_WI', 'snap_TX', 'snap_CA', 'item_id', 'dept_id', 'cat_id', 'store_id', 'state_id', 'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
    "        'tm_d','tm_w','tm_m','tm_y','tm_wm','tm_dw','tm_w_end', 'd']\n",
    "cont = [x for x in features if x not in cat_m]\n",
    "# cont = []\n",
    "procs = [Categorify]\n",
    "\n",
    "cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to 1295.30 Mb (55.4% reduction)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = grid_df[cont].copy()\n",
    "df = df.astype('float32', errors='ignore')\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "def fix_missing(df, col, name, na_dict):\n",
    "    \n",
    "    if is_numeric_dtype(col):\n",
    "        \n",
    "        if pd.isnull(col).sum() or (name in na_dict):\n",
    "                df[name+'_na'] = pd.isnull(col)\n",
    "                filler = na_dict[name] if name in na_dict else col.median()\n",
    "                df[name] = col.fillna(filler)\n",
    "                na_dict[name] = filler\n",
    "    return na_dict\n",
    "na_dict = {}\n",
    "na_dict_initial = na_dict.copy()\n",
    "for n,c in df.items():\n",
    "    na_dict = fix_missing(df, c, n, na_dict)\n",
    "df.drop([a + '_na' for a in list(set(na_dict.keys())) ], axis=1, inplace=True)\n",
    "na_dict\n",
    "means,stds = {},{}\n",
    "cont.remove('sales')\n",
    "for n in cont:\n",
    "    means[n],stds[n] = df[n].mean(),df[n].std()\n",
    "    df[n] = (df[n]-means[n]) / (1e-7 + stds[n])\n",
    "grid_df.drop(cont, axis=1, inplace=True)\n",
    "for c in cont:\n",
    "    grid_df[cont] = df[cont]\n",
    "grid_df = reduce_mem_usage(grid_df)\n",
    "del df\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_df['sales'] = grid_df.sales.fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>cat_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>...</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>price_std</th>\n",
       "      <th>price_mean</th>\n",
       "      <th>price_norm</th>\n",
       "      <th>price_nunique</th>\n",
       "      <th>item_nunique</th>\n",
       "      <th>price_momentum</th>\n",
       "      <th>price_momentum_m</th>\n",
       "      <th>price_momentum_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>HOBBIES_1_001_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_001</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-03-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.492188</td>\n",
       "      <td>1.451172</td>\n",
       "      <td>0.074524</td>\n",
       "      <td>1.223633</td>\n",
       "      <td>0.550293</td>\n",
       "      <td>0.184204</td>\n",
       "      <td>-0.968750</td>\n",
       "      <td>0.661621</td>\n",
       "      <td>0.106750</td>\n",
       "      <td>1.091797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>HOBBIES_1_002_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_002</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-03-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067261</td>\n",
       "      <td>0.120850</td>\n",
       "      <td>-0.635254</td>\n",
       "      <td>-0.033356</td>\n",
       "      <td>1.072266</td>\n",
       "      <td>-0.909180</td>\n",
       "      <td>0.876953</td>\n",
       "      <td>0.661621</td>\n",
       "      <td>0.106750</td>\n",
       "      <td>1.091797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>HOBBIES_1_003_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_003</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2014-03-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.345459</td>\n",
       "      <td>-0.189331</td>\n",
       "      <td>-0.635254</td>\n",
       "      <td>-0.324463</td>\n",
       "      <td>1.072266</td>\n",
       "      <td>-0.909180</td>\n",
       "      <td>0.686523</td>\n",
       "      <td>0.661621</td>\n",
       "      <td>0.106750</td>\n",
       "      <td>1.091797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>HOBBIES_1_004_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_004</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1155</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2014-03-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119019</td>\n",
       "      <td>0.235352</td>\n",
       "      <td>0.042633</td>\n",
       "      <td>0.128662</td>\n",
       "      <td>1.072266</td>\n",
       "      <td>-0.362549</td>\n",
       "      <td>-1.012695</td>\n",
       "      <td>0.661621</td>\n",
       "      <td>0.594238</td>\n",
       "      <td>1.091797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>HOBBIES_1_005_CA_1_validation</td>\n",
       "      <td>HOBBIES_1_005</td>\n",
       "      <td>HOBBIES_1</td>\n",
       "      <td>HOBBIES</td>\n",
       "      <td>CA_1</td>\n",
       "      <td>CA</td>\n",
       "      <td>1155</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-03-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.314941</td>\n",
       "      <td>-0.341553</td>\n",
       "      <td>0.065430</td>\n",
       "      <td>-0.333008</td>\n",
       "      <td>1.072266</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>-0.954102</td>\n",
       "      <td>0.661621</td>\n",
       "      <td>0.763672</td>\n",
       "      <td>1.292969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23388952</td>\n",
       "      <td>FOODS_3_823_WI_3_validation</td>\n",
       "      <td>FOODS_3_823</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>1941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.342773</td>\n",
       "      <td>-0.341553</td>\n",
       "      <td>0.165771</td>\n",
       "      <td>-0.373779</td>\n",
       "      <td>1.072266</td>\n",
       "      <td>1.277344</td>\n",
       "      <td>1.975586</td>\n",
       "      <td>0.661621</td>\n",
       "      <td>0.742676</td>\n",
       "      <td>1.236328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23388953</td>\n",
       "      <td>FOODS_3_824_WI_3_validation</td>\n",
       "      <td>FOODS_3_824</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>1941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426270</td>\n",
       "      <td>-0.490479</td>\n",
       "      <td>0.546387</td>\n",
       "      <td>-0.458984</td>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.730957</td>\n",
       "      <td>0.935547</td>\n",
       "      <td>0.661621</td>\n",
       "      <td>0.043182</td>\n",
       "      <td>1.816406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23388954</td>\n",
       "      <td>FOODS_3_825_WI_3_validation</td>\n",
       "      <td>FOODS_3_825</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>1941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046234</td>\n",
       "      <td>0.123901</td>\n",
       "      <td>0.244873</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>0.726074</td>\n",
       "      <td>0.184204</td>\n",
       "      <td>1.155273</td>\n",
       "      <td>0.661621</td>\n",
       "      <td>-0.634766</td>\n",
       "      <td>1.091797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23388955</td>\n",
       "      <td>FOODS_3_826_WI_3_validation</td>\n",
       "      <td>FOODS_3_826</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>1941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.815430</td>\n",
       "      <td>-0.713867</td>\n",
       "      <td>-0.635254</td>\n",
       "      <td>-0.816406</td>\n",
       "      <td>1.072266</td>\n",
       "      <td>-0.909180</td>\n",
       "      <td>-0.397461</td>\n",
       "      <td>0.661621</td>\n",
       "      <td>0.106750</td>\n",
       "      <td>1.091797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23388956</td>\n",
       "      <td>FOODS_3_827_WI_3_validation</td>\n",
       "      <td>FOODS_3_827</td>\n",
       "      <td>FOODS_3</td>\n",
       "      <td>FOODS</td>\n",
       "      <td>WI_3</td>\n",
       "      <td>WI</td>\n",
       "      <td>1941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2016-05-22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.893555</td>\n",
       "      <td>-0.800781</td>\n",
       "      <td>-0.635254</td>\n",
       "      <td>-0.897949</td>\n",
       "      <td>1.072266</td>\n",
       "      <td>-0.909180</td>\n",
       "      <td>1.038086</td>\n",
       "      <td>0.661621</td>\n",
       "      <td>0.106750</td>\n",
       "      <td>1.091797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23388957 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id        item_id    dept_id   cat_id  \\\n",
       "0         HOBBIES_1_001_CA_1_validation  HOBBIES_1_001  HOBBIES_1  HOBBIES   \n",
       "1         HOBBIES_1_002_CA_1_validation  HOBBIES_1_002  HOBBIES_1  HOBBIES   \n",
       "2         HOBBIES_1_003_CA_1_validation  HOBBIES_1_003  HOBBIES_1  HOBBIES   \n",
       "3         HOBBIES_1_004_CA_1_validation  HOBBIES_1_004  HOBBIES_1  HOBBIES   \n",
       "4         HOBBIES_1_005_CA_1_validation  HOBBIES_1_005  HOBBIES_1  HOBBIES   \n",
       "...                                 ...            ...        ...      ...   \n",
       "23388952    FOODS_3_823_WI_3_validation    FOODS_3_823    FOODS_3    FOODS   \n",
       "23388953    FOODS_3_824_WI_3_validation    FOODS_3_824    FOODS_3    FOODS   \n",
       "23388954    FOODS_3_825_WI_3_validation    FOODS_3_825    FOODS_3    FOODS   \n",
       "23388955    FOODS_3_826_WI_3_validation    FOODS_3_826    FOODS_3    FOODS   \n",
       "23388956    FOODS_3_827_WI_3_validation    FOODS_3_827    FOODS_3    FOODS   \n",
       "\n",
       "         store_id state_id     d  sales       date event_name_1  ...  \\\n",
       "0            CA_1       CA  1155    0.0 2014-03-28          NaN  ...   \n",
       "1            CA_1       CA  1155    0.0 2014-03-28          NaN  ...   \n",
       "2            CA_1       CA  1155    0.0 2014-03-28          NaN  ...   \n",
       "3            CA_1       CA  1155    2.0 2014-03-28          NaN  ...   \n",
       "4            CA_1       CA  1155    1.0 2014-03-28          NaN  ...   \n",
       "...           ...      ...   ...    ...        ...          ...  ...   \n",
       "23388952     WI_3       WI  1941    0.0 2016-05-22          NaN  ...   \n",
       "23388953     WI_3       WI  1941    0.0 2016-05-22          NaN  ...   \n",
       "23388954     WI_3       WI  1941    0.0 2016-05-22          NaN  ...   \n",
       "23388955     WI_3       WI  1941    0.0 2016-05-22          NaN  ...   \n",
       "23388956     WI_3       WI  1941    0.0 2016-05-22          NaN  ...   \n",
       "\n",
       "         price_max price_min price_std price_mean price_norm price_nunique  \\\n",
       "0         1.492188  1.451172  0.074524   1.223633   0.550293      0.184204   \n",
       "1        -0.067261  0.120850 -0.635254  -0.033356   1.072266     -0.909180   \n",
       "2        -0.345459 -0.189331 -0.635254  -0.324463   1.072266     -0.909180   \n",
       "3         0.119019  0.235352  0.042633   0.128662   1.072266     -0.362549   \n",
       "4        -0.314941 -0.341553  0.065430  -0.333008   1.072266      0.730957   \n",
       "...            ...       ...       ...        ...        ...           ...   \n",
       "23388952 -0.342773 -0.341553  0.165771  -0.373779   1.072266      1.277344   \n",
       "23388953 -0.426270 -0.490479  0.546387  -0.458984   0.789062      0.730957   \n",
       "23388954  0.046234  0.123901  0.244873   0.009270   0.726074      0.184204   \n",
       "23388955 -0.815430 -0.713867 -0.635254  -0.816406   1.072266     -0.909180   \n",
       "23388956 -0.893555 -0.800781 -0.635254  -0.897949   1.072266     -0.909180   \n",
       "\n",
       "          item_nunique  price_momentum  price_momentum_m  price_momentum_y  \n",
       "0            -0.968750        0.661621          0.106750          1.091797  \n",
       "1             0.876953        0.661621          0.106750          1.091797  \n",
       "2             0.686523        0.661621          0.106750          1.091797  \n",
       "3            -1.012695        0.661621          0.594238          1.091797  \n",
       "4            -0.954102        0.661621          0.763672          1.292969  \n",
       "...                ...             ...               ...               ...  \n",
       "23388952      1.975586        0.661621          0.742676          1.236328  \n",
       "23388953      0.935547        0.661621          0.043182          1.816406  \n",
       "23388954      1.155273        0.661621         -0.634766          1.091797  \n",
       "23388955     -0.397461        0.661621          0.106750          1.091797  \n",
       "23388956      1.038086        0.661621          0.106750          1.091797  \n",
       "\n",
       "[23388957 rows x 35 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/shanmugam/fastai/m5'\n",
    "bs = 256\n",
    "tab_db = (TabularList.from_df(grid_df, cat_names=cat_m, cont_names=cont, procs=procs, path=path)\n",
    "#                             .split_by_idxs(train_idx=list(range(0,47373650)),valid_idx=list(range(47373650,48227369)))\n",
    "                            .split_by_idx(list(range(21681517,22535237)))\n",
    "                            .label_from_df(cols='sales')\n",
    "                             .add_test((TabularList.from_df(grid_df.iloc[22535237:].copy(), cat_names=cat_m, cont_names=cont, path=path, procs=procs)), label=0)\n",
    "                            .databunch(bs=bs, num_workers=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = grid_df.iloc[22535237:].copy()\n",
    "del grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "?tabular_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = tabular_learner(tab_db, layers=[1000,500], metrics=rmse, ps=[0.001,0.01], emb_drop=0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='0' class='' max='1', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.00% [0/1 00:00<00:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='83' class='' max='88028', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      0.09% [83/88028 00:02<52:46 24.5267]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find()\n",
    "learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>root_mean_squared_error</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7.693470</td>\n",
       "      <td>17.131300</td>\n",
       "      <td>3.152077</td>\n",
       "      <td>24:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit(1, 1e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds, _ = learn.get_preds(DatasetType.Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function list.index(value, start=0, stop=9223372036854775807, /)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.callback_fns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03797925263643265,\n",
       " 0.05904652923345566,\n",
       " -0.1695878505706787,\n",
       " 0.9986572861671448,\n",
       " 0.1614953875541687,\n",
       " 0.010784462094306946,\n",
       " -0.019554011523723602,\n",
       " 0.8582507967948914,\n",
       " 0.20656219124794006,\n",
       " -0.20753541588783264,\n",
       " -0.05346430093050003,\n",
       " -0.054746128618717194,\n",
       " -0.18423578143119812,\n",
       " 0.4432402551174164,\n",
       " 1.0308067798614502,\n",
       " 0.9051096439361572,\n",
       " 0.01572582870721817,\n",
       " 0.11733124405145645,\n",
       " 0.7153828740119934,\n",
       " 0.17082712054252625,\n",
       " 0.19324588775634766,\n",
       " 0.013149142265319824,\n",
       " -0.26814329624176025,\n",
       " 0.17961126565933228,\n",
       " 0.2967551648616791,\n",
       " 0.34653133153915405,\n",
       " 0.39339005947113037,\n",
       " 0.3892109990119934,\n",
       " 0.2592180371284485,\n",
       " 0.6039471626281738,\n",
       " 0.056727536022663116,\n",
       " 0.47435396909713745,\n",
       " 0.23848861455917358,\n",
       " -0.11582378298044205,\n",
       " -0.4054129123687744,\n",
       " -0.4721883535385132,\n",
       " 0.28564661741256714,\n",
       " 0.10354916751384735,\n",
       " 0.02061154693365097,\n",
       " 0.37444743514060974,\n",
       " 0.12224002182483673,\n",
       " 0.10355448722839355,\n",
       " 0.6007475256919861,\n",
       " -0.32800233364105225,\n",
       " 0.08124806731939316,\n",
       " 0.12501376867294312,\n",
       " 0.14004644751548767,\n",
       " 1.4805872440338135,\n",
       " -0.05152345448732376,\n",
       " 0.48972970247268677,\n",
       " 0.17232686281204224,\n",
       " -0.11477337032556534,\n",
       " -0.009348370134830475,\n",
       " -0.09685198217630386,\n",
       " 0.4238791763782501,\n",
       " 0.28869038820266724,\n",
       " 0.17537516355514526,\n",
       " -0.23592427372932434,\n",
       " 0.20373785495758057,\n",
       " 0.1259198635816574,\n",
       " -0.5256006717681885,\n",
       " 0.0988105908036232,\n",
       " 0.23780286312103271,\n",
       " -0.06913617998361588,\n",
       " -0.20017555356025696,\n",
       " 0.2141728699207306,\n",
       " 0.10563188046216965,\n",
       " 0.42616015672683716,\n",
       " -0.14250943064689636,\n",
       " -0.27933743596076965,\n",
       " 0.25119855999946594,\n",
       " 0.29640644788742065,\n",
       " 0.03878413140773773,\n",
       " 0.24334871768951416,\n",
       " 0.1948051154613495,\n",
       " 0.4758484661579132,\n",
       " 0.1368444263935089,\n",
       " 0.04031256586313248,\n",
       " 0.10752508789300919,\n",
       " 0.04811149090528488,\n",
       " 0.174366295337677,\n",
       " -0.05157924443483353,\n",
       " 0.05073723942041397,\n",
       " 0.11566727608442307,\n",
       " 0.21707776188850403,\n",
       " 0.061492808163166046,\n",
       " 0.20111346244812012,\n",
       " -0.07502757757902145,\n",
       " -0.27033859491348267,\n",
       " -0.1027500107884407,\n",
       " 0.30936509370803833,\n",
       " 0.27796459197998047,\n",
       " -0.12884870171546936,\n",
       " 0.22530336678028107,\n",
       " -0.0429268553853035,\n",
       " 0.22344601154327393,\n",
       " 0.38598063588142395,\n",
       " 0.16170203685760498,\n",
       " 0.8190142512321472,\n",
       " 0.8339553475379944,\n",
       " 0.23940187692642212,\n",
       " -0.047689102590084076,\n",
       " -0.24396660923957825,\n",
       " 0.6673685312271118,\n",
       " 0.035333968698978424,\n",
       " -0.0038750842213630676,\n",
       " -0.3225339651107788,\n",
       " -0.3975263833999634,\n",
       " -0.36012452840805054,\n",
       " 0.2044323831796646,\n",
       " -0.057534314692020416,\n",
       " -0.1690380871295929,\n",
       " 0.17060953378677368,\n",
       " 0.14620274305343628,\n",
       " -0.014266759157180786,\n",
       " 0.014442376792430878,\n",
       " -0.2530062794685364,\n",
       " 0.012202657759189606,\n",
       " -0.05101994425058365,\n",
       " 0.4608558416366577,\n",
       " -0.04780248552560806,\n",
       " -0.06211633235216141,\n",
       " -0.48131996393203735,\n",
       " 0.061103567481040955,\n",
       " 0.19621476531028748,\n",
       " 0.17682036757469177,\n",
       " -0.02851080149412155,\n",
       " -0.31533434987068176,\n",
       " 0.037419743835926056,\n",
       " 0.6467191576957703,\n",
       " 0.14065003395080566,\n",
       " -0.11365502327680588,\n",
       " -0.11605317145586014,\n",
       " -0.10915117710828781,\n",
       " 0.10560926049947739,\n",
       " -0.1541382074356079,\n",
       " 0.21001744270324707,\n",
       " 0.21134212613105774,\n",
       " 0.18392035365104675,\n",
       " 0.4405146837234497,\n",
       " -0.04200435429811478,\n",
       " -0.09785745292901993,\n",
       " 0.9650424122810364,\n",
       " 0.2345224916934967,\n",
       " -0.10567588359117508,\n",
       " 0.24231934547424316,\n",
       " 0.21114152669906616,\n",
       " -0.17959526181221008,\n",
       " 0.5729391574859619,\n",
       " 0.4663154184818268,\n",
       " 0.6850106120109558,\n",
       " -0.1740720570087433,\n",
       " 0.35211125016212463,\n",
       " 1.9475703239440918,\n",
       " 0.23917156457901,\n",
       " 0.4333621561527252,\n",
       " -0.12236592918634415,\n",
       " 0.00520431250333786,\n",
       " -0.043300561606884,\n",
       " 0.15538789331912994,\n",
       " 0.06387688964605331,\n",
       " 0.05844000726938248,\n",
       " 0.07173074036836624,\n",
       " 0.23184683918952942,\n",
       " 0.1289082020521164,\n",
       " 0.08581015467643738,\n",
       " -0.12944623827934265,\n",
       " -0.27856481075286865,\n",
       " 0.13298165798187256,\n",
       " 0.03324010223150253,\n",
       " -0.2610166072845459,\n",
       " 0.23037037253379822,\n",
       " 0.15109342336654663,\n",
       " 1.1226305961608887,\n",
       " 0.1885327398777008,\n",
       " 0.242270827293396,\n",
       " -0.3567441701889038,\n",
       " -0.029127396643161774,\n",
       " 0.23472806811332703,\n",
       " -0.09590595215559006,\n",
       " 0.2637312114238739,\n",
       " 0.05823548883199692,\n",
       " 0.03386860340833664,\n",
       " 0.8060228228569031,\n",
       " -0.05025450140237808,\n",
       " -0.39295241236686707,\n",
       " -0.40731656551361084,\n",
       " 0.1721762716770172,\n",
       " 0.16937866806983948,\n",
       " 0.28606629371643066,\n",
       " 0.2090844213962555,\n",
       " -0.04720040410757065,\n",
       " -0.16451820731163025,\n",
       " 0.05542110651731491,\n",
       " 0.35512131452560425,\n",
       " 0.22692087292671204,\n",
       " 0.3146987855434418,\n",
       " 0.0559232160449028,\n",
       " -0.1577666699886322,\n",
       " -0.08182526379823685,\n",
       " -0.4273286461830139,\n",
       " 0.08839762210845947,\n",
       " 0.619426429271698,\n",
       " 0.22224107384681702,\n",
       " 0.4948338568210602,\n",
       " 0.007670663297176361,\n",
       " 0.13536593317985535,\n",
       " 0.25902634859085083,\n",
       " -0.08106578141450882,\n",
       " 0.1660301685333252,\n",
       " 0.02573268860578537,\n",
       " -0.023625679314136505,\n",
       " -0.14573130011558533,\n",
       " -0.009259767830371857,\n",
       " -0.14525267481803894,\n",
       " 0.0230158269405365,\n",
       " 0.03754328936338425,\n",
       " 0.7009666562080383,\n",
       " -0.053591616451740265,\n",
       " -0.2159808874130249,\n",
       " 0.21029096841812134,\n",
       " -0.029818199574947357,\n",
       " -0.11910346895456314,\n",
       " 0.14840292930603027,\n",
       " 0.4009493589401245,\n",
       " 0.8304007649421692,\n",
       " -0.2285669445991516,\n",
       " 0.6109221577644348,\n",
       " 0.40849655866622925,\n",
       " 0.06903272122144699,\n",
       " 0.11114679276943207,\n",
       " -0.02041255682706833,\n",
       " 0.04641511291265488,\n",
       " 1.0733997821807861,\n",
       " 0.08281766623258591,\n",
       " 0.06066601723432541,\n",
       " 0.7717384099960327,\n",
       " 0.12496323138475418,\n",
       " -0.02432117611169815,\n",
       " 0.20397402346134186,\n",
       " 0.06735063344240189,\n",
       " 0.20794567465782166,\n",
       " -0.01648423820734024,\n",
       " 0.17530757188796997,\n",
       " 0.47344884276390076,\n",
       " -0.20118945837020874,\n",
       " 1.2931499481201172,\n",
       " -0.033709727227687836,\n",
       " 0.6637740731239319,\n",
       " -0.29868751764297485,\n",
       " 0.0763884112238884,\n",
       " -0.25030338764190674,\n",
       " 0.07689234614372253,\n",
       " 0.3614148497581482,\n",
       " 0.18971452116966248,\n",
       " 0.175165057182312,\n",
       " 0.05419962853193283,\n",
       " 0.08809106796979904,\n",
       " -0.05722569674253464,\n",
       " -0.14105844497680664,\n",
       " 1.021713137626648,\n",
       " -0.05951244384050369,\n",
       " 0.06406233459711075,\n",
       " -0.12762564420700073,\n",
       " -0.05875670164823532,\n",
       " 0.11143796890974045,\n",
       " -0.10751398652791977,\n",
       " 0.2833818793296814,\n",
       " 0.394915372133255,\n",
       " 0.08318233489990234,\n",
       " 0.32254019379615784,\n",
       " 0.27833449840545654,\n",
       " -0.09700054675340652,\n",
       " -0.12232213467359543,\n",
       " -0.37825578451156616,\n",
       " -0.20198023319244385,\n",
       " -0.0739043578505516,\n",
       " 0.0012754425406455994,\n",
       " 0.5626136064529419,\n",
       " -0.03312712162733078,\n",
       " 0.23168039321899414,\n",
       " 0.15491575002670288,\n",
       " 0.16858986020088196,\n",
       " -0.2238827347755432,\n",
       " 0.2754042446613312,\n",
       " 0.03707638382911682,\n",
       " 0.6726787686347961,\n",
       " 0.13120177388191223,\n",
       " 0.7314644455909729,\n",
       " -0.06761596351861954,\n",
       " -0.36573147773742676,\n",
       " 0.006518624722957611,\n",
       " 0.1876365840435028,\n",
       " -0.14298930764198303,\n",
       " 0.22057229280471802,\n",
       " 0.09742721170186996,\n",
       " -0.03190139681100845,\n",
       " 0.15771915018558502,\n",
       " -0.058977626264095306,\n",
       " -0.14520010352134705,\n",
       " 0.02394283562898636,\n",
       " -0.013221390545368195,\n",
       " -0.3930375576019287,\n",
       " 0.23666617274284363,\n",
       " -0.30568426847457886,\n",
       " 0.01675347238779068,\n",
       " -0.6014209389686584,\n",
       " -0.14229196310043335,\n",
       " 0.4253119230270386,\n",
       " -0.19552764296531677,\n",
       " 0.8611551523208618,\n",
       " 0.06076257303357124,\n",
       " 0.16409341990947723,\n",
       " 0.05897047370672226,\n",
       " 0.14861196279525757,\n",
       " 0.7005918025970459,\n",
       " -0.2639596462249756,\n",
       " -0.1963033378124237,\n",
       " -0.021444551646709442,\n",
       " -0.028337903320789337,\n",
       " 0.03070690482854843,\n",
       " 0.21270787715911865,\n",
       " -0.4567984938621521,\n",
       " -0.08153720945119858,\n",
       " -0.010966725647449493,\n",
       " 0.3246304988861084,\n",
       " 0.12650272250175476,\n",
       " -0.22245383262634277,\n",
       " 0.4785507023334503,\n",
       " 0.22316226363182068,\n",
       " 0.2676171362400055,\n",
       " -0.08673051744699478,\n",
       " 0.7651635408401489,\n",
       " 0.5235812664031982,\n",
       " 0.4636880159378052,\n",
       " -0.02376163750886917,\n",
       " 0.31617996096611023,\n",
       " -0.00971793383359909,\n",
       " -0.032767899334430695,\n",
       " 0.9194217324256897,\n",
       " -0.11698224395513535,\n",
       " -0.2440810203552246,\n",
       " -0.037100352346897125,\n",
       " 0.09540071338415146,\n",
       " 0.3201058506965637,\n",
       " 3.9808173179626465,\n",
       " 0.10516553372144699,\n",
       " -0.10409984737634659,\n",
       " 0.6621906161308289,\n",
       " 0.19534683227539062,\n",
       " -0.34395456314086914,\n",
       " 0.2164086401462555,\n",
       " 0.5233052372932434,\n",
       " 0.15031319856643677,\n",
       " -0.3229330778121948,\n",
       " 0.18413719534873962,\n",
       " 0.0876697525382042,\n",
       " 0.021914489567279816,\n",
       " 0.16271823644638062,\n",
       " 0.11847426742315292,\n",
       " 0.09838726371526718,\n",
       " 0.7209833264350891,\n",
       " 1.097800612449646,\n",
       " 0.2056678831577301,\n",
       " 0.3148426115512848,\n",
       " 0.16266456246376038,\n",
       " 0.022252485156059265,\n",
       " 0.2826363444328308,\n",
       " 0.049623362720012665,\n",
       " 0.2578730881214142,\n",
       " 0.10267403721809387,\n",
       " 0.2949043810367584,\n",
       " 0.9811853766441345,\n",
       " -0.26775145530700684,\n",
       " 0.17667847871780396,\n",
       " 0.04486335068941116,\n",
       " -0.1311904788017273,\n",
       " 0.1471630036830902,\n",
       " 0.3991161286830902,\n",
       " 0.03635471314191818,\n",
       " -0.4322022795677185,\n",
       " 0.33392688632011414,\n",
       " 0.03452902287244797,\n",
       " 0.1619260311126709,\n",
       " 1.3051016330718994,\n",
       " 0.08275123685598373,\n",
       " -0.17834335565567017,\n",
       " -0.34301039576530457,\n",
       " -0.011407457292079926,\n",
       " 0.26596400141716003,\n",
       " -0.15258145332336426,\n",
       " -0.035245560109615326,\n",
       " -0.2234266698360443,\n",
       " 0.0145803764462471,\n",
       " 0.4212552309036255,\n",
       " 0.9822391867637634,\n",
       " 0.07588266581296921,\n",
       " 0.0028073862195014954,\n",
       " 0.17223268747329712,\n",
       " 0.19963768124580383,\n",
       " -0.0242372527718544,\n",
       " 0.8192611336708069,\n",
       " -0.22352120280265808,\n",
       " 0.32111090421676636,\n",
       " -0.13319578766822815,\n",
       " 0.23561397194862366,\n",
       " 0.17977862060070038,\n",
       " 0.3004593253135681,\n",
       " 0.05495596304535866,\n",
       " 0.2010338306427002,\n",
       " 0.13836154341697693,\n",
       " 0.15061751008033752,\n",
       " 0.2483847439289093,\n",
       " -0.026176325976848602,\n",
       " 0.3064403235912323,\n",
       " 0.13606266677379608,\n",
       " -0.08848000317811966,\n",
       " -0.4059634804725647,\n",
       " -0.10391242057085037,\n",
       " 0.026061393320560455,\n",
       " -0.10348453372716904,\n",
       " 0.20627564191818237,\n",
       " -0.1555078625679016,\n",
       " -0.14408248662948608,\n",
       " 0.134237140417099,\n",
       " -0.3684563934803009,\n",
       " -0.5269721150398254,\n",
       " -0.13495230674743652,\n",
       " -0.28903844952583313,\n",
       " -0.4688528776168823,\n",
       " -0.652877926826477,\n",
       " 0.07316695898771286,\n",
       " -0.49563688039779663,\n",
       " -0.024913929402828217,\n",
       " -0.0916106179356575,\n",
       " -0.14027005434036255,\n",
       " -0.4209517240524292,\n",
       " 0.16803953051567078,\n",
       " -0.29381823539733887,\n",
       " 0.23350286483764648,\n",
       " -0.5546460747718811,\n",
       " 0.03323671966791153,\n",
       " -0.259531170129776,\n",
       " -0.45062577724456787,\n",
       " -0.4263074994087219,\n",
       " -0.8686063885688782,\n",
       " 0.00908186286687851,\n",
       " -0.4336852431297302,\n",
       " -0.012868233025074005,\n",
       " -0.4855085015296936,\n",
       " 0.24374428391456604,\n",
       " 0.05844362825155258,\n",
       " -0.6396893262863159,\n",
       " -0.1774771809577942,\n",
       " 0.11208850890398026,\n",
       " -0.45698338747024536,\n",
       " -0.1100103035569191,\n",
       " -0.4886532425880432,\n",
       " 0.0760655403137207,\n",
       " -0.007158823311328888,\n",
       " -0.13543066382408142,\n",
       " -0.4112861156463623,\n",
       " -0.5869380235671997,\n",
       " -0.30165863037109375,\n",
       " -0.5667955279350281,\n",
       " -0.2682148218154907,\n",
       " -0.77562016248703,\n",
       " 0.045426540076732635,\n",
       " -0.03887469321489334,\n",
       " -0.00016889721155166626,\n",
       " -0.6001409888267517,\n",
       " -0.9767124056816101,\n",
       " -0.20869404077529907,\n",
       " -0.1908816397190094,\n",
       " 0.3504316508769989,\n",
       " -0.34093204140663147,\n",
       " -0.3005206286907196,\n",
       " 0.3132154941558838,\n",
       " -0.5712056756019592,\n",
       " -0.4675423502922058,\n",
       " -0.4469890594482422,\n",
       " 0.16252225637435913,\n",
       " -0.143854558467865,\n",
       " -0.7313593029975891,\n",
       " -0.023857809603214264,\n",
       " 0.0355948731303215,\n",
       " -0.4623340964317322,\n",
       " 0.11823522299528122,\n",
       " -0.5263069868087769,\n",
       " 0.15285015106201172,\n",
       " 0.32436850666999817,\n",
       " -0.23232674598693848,\n",
       " -0.1061469092965126,\n",
       " -0.2175915539264679,\n",
       " -0.42722463607788086,\n",
       " -0.01720251888036728,\n",
       " -0.19140836596488953,\n",
       " -0.29508906602859497,\n",
       " -0.3488779067993164,\n",
       " -0.14176738262176514,\n",
       " -0.2607108950614929,\n",
       " -0.4785010814666748,\n",
       " -0.4661794900894165,\n",
       " -0.004394344985485077,\n",
       " -0.06737557798624039,\n",
       " -0.5213839411735535,\n",
       " -0.3429186940193176,\n",
       " 0.15111929178237915,\n",
       " -0.1810254454612732,\n",
       " -0.1882244050502777,\n",
       " -0.3320533335208893,\n",
       " -0.014870621263980865,\n",
       " -0.462806761264801,\n",
       " -0.41473454236984253,\n",
       " -0.48346006870269775,\n",
       " -0.46779775619506836,\n",
       " -0.2600878179073334,\n",
       " 0.30128878355026245,\n",
       " -0.4056200385093689,\n",
       " -0.006524480879306793,\n",
       " -0.38937947154045105,\n",
       " -0.449238121509552,\n",
       " -0.31224608421325684,\n",
       " -0.16375625133514404,\n",
       " -0.16560745239257812,\n",
       " 0.11874601989984512,\n",
       " -0.11274377256631851,\n",
       " -0.3249308466911316,\n",
       " 0.012282006442546844,\n",
       " 0.037628643214702606,\n",
       " -0.24016982316970825,\n",
       " 0.01221119612455368,\n",
       " -0.30436500906944275,\n",
       " 0.24968385696411133,\n",
       " -0.3638312816619873,\n",
       " 0.09973324090242386,\n",
       " -0.01165366917848587,\n",
       " -0.4145473837852478,\n",
       " -0.3656962513923645,\n",
       " -0.23731043934822083,\n",
       " -0.8616940975189209,\n",
       " -0.13013413548469543,\n",
       " -0.08349505811929703,\n",
       " -0.19901052117347717,\n",
       " 0.3214307725429535,\n",
       " 0.1056956872344017,\n",
       " -0.015158459544181824,\n",
       " -0.22580984234809875,\n",
       " -0.3161748945713043,\n",
       " -0.17045897245407104,\n",
       " -0.5239744782447815,\n",
       " -0.5850080847740173,\n",
       " -0.0663248673081398,\n",
       " -0.7079760432243347,\n",
       " 0.016941040754318237,\n",
       " 0.0563783124089241,\n",
       " -0.4032509922981262,\n",
       " 0.5926899313926697,\n",
       " -0.36841464042663574,\n",
       " -0.3990374207496643,\n",
       " -0.3735799491405487,\n",
       " -0.20576488971710205,\n",
       " -0.4127364754676819,\n",
       " -0.5383029580116272,\n",
       " 0.13562795519828796,\n",
       " -0.3571586012840271,\n",
       " -0.36627236008644104,\n",
       " 0.030324481427669525,\n",
       " 0.2523951530456543,\n",
       " 0.33962926268577576,\n",
       " 0.34892114996910095,\n",
       " 0.2908317446708679,\n",
       " 0.2858952581882477,\n",
       " 0.172919362783432,\n",
       " 0.24959373474121094,\n",
       " 0.46791160106658936,\n",
       " 0.1565583497285843,\n",
       " 0.3018346130847931,\n",
       " 0.1882099211215973,\n",
       " 0.2008189558982849,\n",
       " 0.03003031760454178,\n",
       " 0.11655491590499878,\n",
       " 0.36719515919685364,\n",
       " 0.47513556480407715,\n",
       " 0.09685622900724411,\n",
       " 0.16192664206027985,\n",
       " 0.2962588369846344,\n",
       " -0.03859401494264603,\n",
       " 0.06610781699419022,\n",
       " 0.024395637214183807,\n",
       " 0.16518379747867584,\n",
       " 0.4160946011543274,\n",
       " -0.07904428988695145,\n",
       " 0.29214635491371155,\n",
       " 0.3447754681110382,\n",
       " 0.7155525088310242,\n",
       " -0.09759686142206192,\n",
       " -0.037847913801670074,\n",
       " -0.1030522957444191,\n",
       " -0.5265303254127502,\n",
       " -0.09510783106088638,\n",
       " 0.5644782781600952,\n",
       " 0.021081171929836273,\n",
       " 0.9666598439216614,\n",
       " -4.2922794818878174e-05,\n",
       " -0.5817857384681702,\n",
       " 0.1061905100941658,\n",
       " 0.21232986450195312,\n",
       " 0.3578413724899292,\n",
       " -0.18656015396118164,\n",
       " 0.38767269253730774,\n",
       " -0.05893198400735855,\n",
       " 0.3923412561416626,\n",
       " 0.38045644760131836,\n",
       " -0.40882134437561035,\n",
       " 0.6727706789970398,\n",
       " 0.0002883598208427429,\n",
       " 0.4773484468460083,\n",
       " 0.30603933334350586,\n",
       " -0.38445568084716797,\n",
       " 0.3063063621520996,\n",
       " 0.24630385637283325,\n",
       " 0.7474933862686157,\n",
       " 0.17109006643295288,\n",
       " 0.2969296872615814,\n",
       " -0.22408217191696167,\n",
       " -0.16688817739486694,\n",
       " -0.04461795836687088,\n",
       " 1.1171282529830933,\n",
       " -0.02391410619020462,\n",
       " 0.37411272525787354,\n",
       " -0.0556434765458107,\n",
       " 0.10662955045700073,\n",
       " 0.4656873345375061,\n",
       " 0.5527453422546387,\n",
       " 0.16774877905845642,\n",
       " -0.2206958830356598,\n",
       " 0.344376802444458,\n",
       " -0.12019971758127213,\n",
       " 0.3594551682472229,\n",
       " 0.2483433485031128,\n",
       " 0.15744321048259735,\n",
       " 0.061067692935466766,\n",
       " 0.09146900475025177,\n",
       " 0.35402750968933105,\n",
       " 0.584879457950592,\n",
       " 0.19323891401290894,\n",
       " 0.14357376098632812,\n",
       " 0.23168745636940002,\n",
       " 0.30853620171546936,\n",
       " 0.41842031478881836,\n",
       " 0.5204430222511292,\n",
       " 0.0020315051078796387,\n",
       " -0.3934509754180908,\n",
       " -0.06602271646261215,\n",
       " 0.0028866752982139587,\n",
       " -0.2661159634590149,\n",
       " 1.0400077104568481,\n",
       " -0.46606117486953735,\n",
       " 0.039428941905498505,\n",
       " -0.023993439972400665,\n",
       " 0.35288915038108826,\n",
       " 0.150603786110878,\n",
       " 0.602078378200531,\n",
       " 0.33086103200912476,\n",
       " -0.17526701092720032,\n",
       " -0.08065440505743027,\n",
       " 0.7184683084487915,\n",
       " 0.45160797238349915,\n",
       " 0.026498056948184967,\n",
       " 0.23266196250915527,\n",
       " 1.7305725812911987,\n",
       " 0.2760601341724396,\n",
       " -0.0666627362370491,\n",
       " 0.29974445700645447,\n",
       " 0.1386534869670868,\n",
       " -0.09616241604089737,\n",
       " -0.16013234853744507,\n",
       " 0.3268226385116577,\n",
       " 0.10084570199251175,\n",
       " 0.13440856337547302,\n",
       " 0.11478026956319809,\n",
       " 0.22788065671920776,\n",
       " 0.10150884836912155,\n",
       " 0.3466263711452484,\n",
       " 0.16797611117362976,\n",
       " 0.24889862537384033,\n",
       " 0.15385672450065613,\n",
       " -0.09478162974119186,\n",
       " 0.1614415943622589,\n",
       " 6.752461194992065e-05,\n",
       " 0.418448805809021,\n",
       " 0.18395933508872986,\n",
       " -0.029505617916584015,\n",
       " -0.23747611045837402,\n",
       " 0.1852695643901825,\n",
       " 0.01688390225172043,\n",
       " 0.16357284784317017,\n",
       " 0.22745119035243988,\n",
       " 0.2001509666442871,\n",
       " 0.352435827255249,\n",
       " 0.21889406442642212,\n",
       " -0.13586682081222534,\n",
       " 0.25174352526664734,\n",
       " 0.19764143228530884,\n",
       " -0.1676959991455078,\n",
       " 0.05141835659742355,\n",
       " 1.0327203273773193,\n",
       " -0.018497057259082794,\n",
       " 0.08184445649385452,\n",
       " 0.19895409047603607,\n",
       " 0.9181308746337891,\n",
       " -0.1505787968635559,\n",
       " 0.1484062671661377,\n",
       " -0.06787825375795364,\n",
       " 0.21393409371376038,\n",
       " 0.26270291209220886,\n",
       " 0.2120698094367981,\n",
       " 0.03438586741685867,\n",
       " 0.1348041296005249,\n",
       " 0.06895174831151962,\n",
       " 0.31602686643600464,\n",
       " 0.17830514907836914,\n",
       " -0.21513819694519043,\n",
       " 0.01849314570426941,\n",
       " 0.7379595041275024,\n",
       " 0.1400967836380005,\n",
       " -0.19313722848892212,\n",
       " 0.0907372459769249,\n",
       " 0.09421136230230331,\n",
       " 0.0834055170416832,\n",
       " 0.13766467571258545,\n",
       " -0.1558125615119934,\n",
       " 0.16264081001281738,\n",
       " 0.35942983627319336,\n",
       " -0.10236120969057083,\n",
       " 0.11159072071313858,\n",
       " 0.5316351652145386,\n",
       " -0.04240860790014267,\n",
       " 0.2793048322200775,\n",
       " 0.30448678135871887,\n",
       " -0.07477987557649612,\n",
       " -0.09656316787004471,\n",
       " -0.3032819628715515,\n",
       " 0.3811984062194824,\n",
       " 0.1846024990081787,\n",
       " 0.49757295846939087,\n",
       " -0.0822267010807991,\n",
       " 0.26144006848335266,\n",
       " 0.11425197869539261,\n",
       " 0.04513569921255112,\n",
       " 1.2470122575759888,\n",
       " 0.09261655062437057,\n",
       " 0.2337946593761444,\n",
       " 0.4285625219345093,\n",
       " 0.129978746175766,\n",
       " 0.39516639709472656,\n",
       " 0.47093135118484497,\n",
       " 0.6559958457946777,\n",
       " -0.39444273710250854,\n",
       " -0.378537118434906,\n",
       " 0.3858514428138733,\n",
       " 0.33965960144996643,\n",
       " 0.01174899935722351,\n",
       " 0.30369091033935547,\n",
       " 0.30259931087493896,\n",
       " -0.06620258837938309,\n",
       " 0.21656084060668945,\n",
       " 0.4414944648742676,\n",
       " 0.16031986474990845,\n",
       " -0.1100849136710167,\n",
       " 0.11367390304803848,\n",
       " 0.007247351109981537,\n",
       " 0.24625131487846375,\n",
       " 0.1743546575307846,\n",
       " 0.03248433768749237,\n",
       " 0.034804873168468475,\n",
       " 0.09293447434902191,\n",
       " -0.043119944632053375,\n",
       " 0.1340276300907135,\n",
       " 0.14954881370067596,\n",
       " -0.02696756273508072,\n",
       " 0.24374857544898987,\n",
       " 0.03346904367208481,\n",
       " -0.14997488260269165,\n",
       " 0.2573837339878082,\n",
       " 0.1730220764875412,\n",
       " 0.2900547385215759,\n",
       " 0.3673451542854309,\n",
       " -0.04789430648088455,\n",
       " 0.03329223394393921,\n",
       " -0.23308447003364563,\n",
       " -0.2145860195159912,\n",
       " 0.1981651782989502,\n",
       " 0.7556588053703308,\n",
       " -0.2153751254081726,\n",
       " 0.2633378803730011,\n",
       " -0.06867343932390213,\n",
       " 0.13618287444114685,\n",
       " 0.059816956520080566,\n",
       " -0.1306767463684082,\n",
       " 0.08378653973340988,\n",
       " 0.3089982867240906,\n",
       " 0.1772674024105072,\n",
       " 0.1115061566233635,\n",
       " 0.38026660680770874,\n",
       " 0.35779935121536255,\n",
       " 0.023641906678676605,\n",
       " 0.10274475067853928,\n",
       " -0.07058892399072647,\n",
       " 0.09906160086393356,\n",
       " -0.02000363916158676,\n",
       " 0.0997968539595604,\n",
       " 0.28292736411094666,\n",
       " 0.4679807424545288,\n",
       " 0.211684912443161,\n",
       " -0.1722266674041748,\n",
       " -0.06828419119119644,\n",
       " 0.4352675676345825,\n",
       " -0.1321561336517334,\n",
       " -0.22251194715499878,\n",
       " 0.35342270135879517,\n",
       " -0.003580428659915924,\n",
       " -0.0834747776389122,\n",
       " 0.1318962275981903,\n",
       " -1.0718817710876465,\n",
       " -0.01545194536447525,\n",
       " 0.1460341215133667,\n",
       " -0.038144551217556,\n",
       " 0.22996455430984497,\n",
       " -0.1508060097694397,\n",
       " 0.4086383581161499,\n",
       " 0.07450272887945175,\n",
       " 0.3399050831794739,\n",
       " -0.08246374875307083,\n",
       " 0.12481971830129623,\n",
       " -0.2650769352912903,\n",
       " 0.14638769626617432,\n",
       " 0.4024590849876404,\n",
       " -0.014856383204460144,\n",
       " 0.16844454407691956,\n",
       " 0.3818904161453247,\n",
       " 0.07976021617650986,\n",
       " 0.05128464847803116,\n",
       " 0.25029873847961426,\n",
       " 0.5969358682632446,\n",
       " 0.15687435865402222,\n",
       " 0.6593299508094788,\n",
       " 0.18202069401741028,\n",
       " 0.18960797786712646,\n",
       " 0.30467650294303894,\n",
       " 0.27046605944633484,\n",
       " 0.6273425221443176,\n",
       " -0.07292283326387405,\n",
       " -0.031829990446567535,\n",
       " -0.016854941844940186,\n",
       " 0.18966513872146606,\n",
       " -0.152028888463974,\n",
       " 0.01744212955236435,\n",
       " 0.2598882019519806,\n",
       " -0.09708908945322037,\n",
       " 0.871577799320221,\n",
       " 0.6953946948051453,\n",
       " 0.20371800661087036,\n",
       " 0.3758913278579712,\n",
       " 0.20322972536087036,\n",
       " -0.023900695145130157,\n",
       " 0.020775623619556427,\n",
       " 0.40871572494506836,\n",
       " 0.23898857831954956,\n",
       " -0.01725364476442337,\n",
       " -0.2339923083782196,\n",
       " 0.027754835784435272,\n",
       " 0.03677581995725632,\n",
       " -0.09231627732515335,\n",
       " 0.203218013048172,\n",
       " 0.44915997982025146,\n",
       " 0.31019866466522217,\n",
       " -0.20258581638336182,\n",
       " 0.41258692741394043,\n",
       " 0.10343325883150101,\n",
       " -0.4034392237663269,\n",
       " 0.285256564617157,\n",
       " -0.4811044931411743,\n",
       " -0.11273898929357529,\n",
       " 0.5256341099739075,\n",
       " 0.7414005398750305,\n",
       " 0.2945798337459564,\n",
       " 0.06620865315198898,\n",
       " 0.10020273178815842,\n",
       " -0.008651942014694214,\n",
       " -0.14250043034553528,\n",
       " 0.7834598422050476,\n",
       " -0.4125496745109558,\n",
       " 0.36463499069213867,\n",
       " 0.19629257917404175,\n",
       " 0.16119664907455444,\n",
       " 0.26431259512901306,\n",
       " 0.16657058894634247,\n",
       " 0.28041312098503113,\n",
       " 0.5265215039253235,\n",
       " -0.08288160711526871,\n",
       " 0.22029435634613037,\n",
       " 0.21861720085144043,\n",
       " -0.018934331834316254,\n",
       " 0.4751238524913788,\n",
       " 0.31923267245292664,\n",
       " 0.2613547444343567,\n",
       " -0.22498387098312378,\n",
       " 0.5166304707527161,\n",
       " 0.34936121106147766,\n",
       " 0.1901022493839264,\n",
       " 0.03422506898641586,\n",
       " 0.12522783875465393,\n",
       " 0.40405839681625366,\n",
       " 0.19315028190612793,\n",
       " 0.19124853610992432,\n",
       " 0.03935018926858902,\n",
       " 0.14594584703445435,\n",
       " 0.19668170809745789,\n",
       " -0.06388015300035477,\n",
       " 0.07374336570501328,\n",
       " 0.018863052129745483,\n",
       " 0.40720340609550476,\n",
       " 0.17562329769134521,\n",
       " -0.14705568552017212,\n",
       " 0.23182302713394165,\n",
       " 0.20369207859039307,\n",
       " 0.49163907766342163,\n",
       " 0.2255980670452118,\n",
       " 0.5840224623680115,\n",
       " 0.5141726136207581,\n",
       " 0.1463833451271057,\n",
       " 0.16953736543655396,\n",
       " 0.28468209505081177,\n",
       " 0.30365148186683655,\n",
       " 0.15149083733558655,\n",
       " -0.22412291169166565,\n",
       " 0.10529603809118271,\n",
       " 0.11541284620761871,\n",
       " 0.3625558018684387,\n",
       " 0.08538217097520828,\n",
       " 0.2861168086528778,\n",
       " 0.30804282426834106,\n",
       " 0.4548504650592804,\n",
       " 0.02732386440038681,\n",
       " 0.5052369832992554,\n",
       " 0.0880652442574501,\n",
       " 0.20559591054916382,\n",
       " 0.09278010576963425,\n",
       " -0.06456025689840317,\n",
       " 0.21508553624153137,\n",
       " 0.31147336959838867,\n",
       " 0.020227715373039246,\n",
       " 1.009453535079956,\n",
       " 0.10377038270235062,\n",
       " 0.33161792159080505,\n",
       " -0.16213911771774292,\n",
       " -0.20335757732391357,\n",
       " 0.01850181818008423,\n",
       " -0.07762403041124344,\n",
       " 0.16231495141983032,\n",
       " 0.30099135637283325,\n",
       " 0.27940449118614197,\n",
       " 1.0152422189712524,\n",
       " 0.5299195647239685,\n",
       " 0.39318960905075073,\n",
       " 0.4789671003818512,\n",
       " 0.4736313819885254,\n",
       " 0.2831020951271057,\n",
       " 0.17117038369178772,\n",
       " -0.24532467126846313,\n",
       " 0.2733478546142578,\n",
       " 0.6403292417526245,\n",
       " -0.34549593925476074,\n",
       " -0.19754791259765625,\n",
       " -0.022184334695339203,\n",
       " -0.12389735132455826,\n",
       " 0.06206279247999191,\n",
       " 0.014700673520565033,\n",
       " 0.37376224994659424,\n",
       " -0.008886046707630157,\n",
       " 0.5917418599128723,\n",
       " 0.022381313145160675,\n",
       " 0.6826046109199524,\n",
       " 0.13906049728393555,\n",
       " 0.16253864765167236,\n",
       " -0.02522725611925125,\n",
       " 0.017684809863567352,\n",
       " 0.41705626249313354,\n",
       " -0.14958456158638,\n",
       " -0.0866800919175148,\n",
       " 0.24274584650993347,\n",
       " 0.06023717671632767,\n",
       " 0.26296818256378174,\n",
       " 0.387913316488266,\n",
       " 1.2997366189956665,\n",
       " 0.2278239130973816,\n",
       " 0.03495519608259201,\n",
       " 0.07241352647542953,\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = preds.squeeze().tolist()\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mem. usage decreased to  2.09 Mb (84.5% reduction)\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIR = \"/home/shanmugam/fastai/m5\"\n",
    "submission = pd.read_csv(f\"{INPUT_DIR}/sample_submission.csv\").pipe(\n",
    "        reduce_mem_usage\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['demand'] = y\n",
    "predictions = sub[['id', 'date', 'demand']]\n",
    "predictions = pd.pivot(predictions, index = 'id', columns = 'date', values = 'demand').reset_index()\n",
    "predictions.columns = ['id'] + ['F' + str(i + 1) for i in range(28)]\n",
    "\n",
    "evaluation_rows = [row for row in submission['id'] if 'evaluation' in row] \n",
    "evaluation = submission[submission['id'].isin(evaluation_rows)]\n",
    "\n",
    "validation = submission[['id']].merge(predictions, on = 'id')\n",
    "final = pd.concat([validation, evaluation])\n",
    "final.to_csv('submission_p.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
